{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ef1b202f",
   "metadata": {},
   "source": [
    "# Data Cleaning\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4192d1f",
   "metadata": {},
   "source": [
    "## Initialize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b304ddae",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abaa3674",
   "metadata": {},
   "source": [
    "## Drop\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "26be5f01",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame()\n",
    "try:\n",
    "    # Drop all rows where col1 > 5\n",
    "    df.drop(df[df['col1']>5].index, inplace = True)\n",
    "    assert df['col1'].max() <= 5\n",
    "except:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18fd2c7a",
   "metadata": {},
   "source": [
    "## Filter & Replace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e85b0b35",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame()\n",
    "try:\n",
    "    # Replace all cell where 'col1' < 5 with 5\n",
    "    df.loc[df['col1']<=5, 'col1'] = 5\n",
    "    assert df['col1'].max() <= 5\n",
    "except:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72dd578c",
   "metadata": {},
   "source": [
    "## Locate duplicated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6e7b5f91",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: []\n",
       "Index: []"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df = pd.DataFrame()\n",
    "try:\n",
    "    # Return boolean series indicating wheather each row is duplicated or not\n",
    "    # keep can be any value of ('first', 'last', False); False to show all duplicated rows\n",
    "    criterion_cols = []\n",
    "    duplicates = df.duplicated(subset=criterion_cols, keep = False)\n",
    "    \n",
    "    # Show duplicated rows\n",
    "    display(df[duplicates].sort_values())\n",
    "except:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77ae3bea",
   "metadata": {},
   "source": [
    "## Drop duplicated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e0e51e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame()\n",
    "try:\n",
    "    criterion_cols = []\n",
    "    df.drop_duplicates(subset=criterion_cols, keep = False, inplace = True)\n",
    "except:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a841cde",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Treat duplicated\n",
    "\n",
    "df = pd.DataFrame()\n",
    "try:\n",
    "    # Combine duplicated rows based on max col1 and mean col2 \n",
    "    df = df.groupby(df.index).agg({'col1':'max', 'col2':'mean'}).reset_index()\n",
    "except:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a9648b9",
   "metadata": {},
   "source": [
    "## Membership Constraints\n",
    "\n",
    "Each column might be constrained to a certain range\n",
    "\n",
    "To find rows that have abnormal values, compare column values with their contraints\n",
    "\n",
    "For example, blood type contains {A, B, AB, O}\n",
    "\n",
    "Use `wrong_blood_types = set(patiens['blood_type'].difference(blood_types)` to find if `patients` dataframe has any abnormal entry for `'blood_type'` column\n",
    "\n",
    "Then, use `has_bad_entry = patients['blood_type].isin(wrong_blood_types)` to retrieve a boolean series that reflects whether each row of `patients` has a bad entry for `'blood_type'`\n",
    "\n",
    "Use `patients[has_bad_entry]` to find rows where `'blood_types'` has an anomaly"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed5e7b84",
   "metadata": {},
   "source": [
    "## Categorize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68db4b46",
   "metadata": {},
   "outputs": [],
   "source": [
    "group_names = ['0-200k', '200k-500k', ' 500k+']\n",
    "try:\n",
    "    df['income_group'] = pd.qcut(df['income'], q = 3, label = group_names)\n",
    "except:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bbfc7f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "ranges = [0,200000, 500000, np.inf]\n",
    "group_names = ['0-200k', '200k-500k', ' 500k+']\n",
    "try:\n",
    "    df['income_group'] = pd.qcut(df['income'], label = group_names, bins = ranges)\n",
    "except:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bda5b959",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace using mapping\n",
    "\n",
    "mapping = {'Microsoft':'DesktopOS',\n",
    "          'MacOS':'DesktopOS',\n",
    "          'IOS':'MobileOS'}\n",
    "\n",
    "try:\n",
    "    df['opereating_system'] = df['operating_system'].replace(mapping)\n",
    "except:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f47225eb",
   "metadata": {},
   "source": [
    "## Treat Date Data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "992d9a00",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    df['date'] = pd.to_datetime(df['date'], infer_datetime_format = True, errors= 'coerce')\n",
    "except:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffc698fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    df['date'] = df['date'].dt.strftime(\"%m-%d-%Y\")\n",
    "except:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe085f14",
   "metadata": {},
   "source": [
    "## Missing Data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "671031fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize missing data distribution in a dataset\n",
    "\n",
    "import missingno as msno\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "try:\n",
    "    msno.matrix(df)\n",
    "    plt.show()\n",
    "except:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9883fb46",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    missing = df[df['col'].isna()]\n",
    "    non_missing = df[~df['col'].isna()]\n",
    "    \n",
    "    # Examine if there exists a systematic character of missing data\n",
    "    display(missing.describe())\n",
    "    display(non_missing.describe())\n",
    "    \n",
    "    # Visualize character\n",
    "    sorted_df = df.sort_values(characters)\n",
    "    msno.matrix(sorted_df)\n",
    "    plt.show\n",
    "except:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23366f9d",
   "metadata": {},
   "source": [
    "## Comparing Strings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66d1ada7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from fuzzywuzzy import fuzz\n",
    "\n",
    "# Similarity score\n",
    "fuzz.WRatio('Reeding', 'Reading')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6da2bc8e",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'fuzzywuzzy'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Input \u001b[0;32mIn [11]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mfuzzywuzzy\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m process\n\u001b[1;32m      4\u001b[0m string \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124ma vs b\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m      5\u001b[0m choices \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mSeries([\u001b[38;5;124m'\u001b[39m\u001b[38;5;124ma vs b\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mb vs a\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124ma vs c\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mc vs d\u001b[39m\u001b[38;5;124m'\u001b[39m])\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'fuzzywuzzy'"
     ]
    }
   ],
   "source": [
    "from fuzzywuzzy import process\n",
    "\n",
    "\n",
    "string = \"a vs b\"\n",
    "choices = pd.Series(['a vs b', 'b vs a', 'a vs c', 'c vs d'])\n",
    "try:\n",
    "    process.extract(string, choices, limit = 2)\n",
    "except:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "10777fbc",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'recordlinkage'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Input \u001b[0;32mIn [13]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mrecordlinkage\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m      4\u001b[0m     idnexer \u001b[38;5;241m=\u001b[39m recordlinkage\u001b[38;5;241m.\u001b[39mIndex()\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'recordlinkage'"
     ]
    }
   ],
   "source": [
    "import recordlinkage\n",
    "\n",
    "try:\n",
    "    idnexer = recordlinkage.Index()\n",
    "\n",
    "    indexer.block('col1')\n",
    "\n",
    "    pairs = indexer.index(df1, df2)\n",
    "    \n",
    "    compare_cl = recordlinkage.Compare()\n",
    "    \n",
    "    # exact match\n",
    "    compare_cl.exact('col1', 'col1', label = 'col1')\n",
    "    \n",
    "    # similar match\n",
    "    compare_cl.string('col1', 'col1', threshold = 0.85, label = 'col1')\n",
    "    \n",
    "    potential_matches = companre_cl.compute(pairs, df1, df2)\n",
    "    \n",
    "    matches = potential_matches[potential_matches.sum(axis = 1) > 2]\n",
    "    \n",
    "    duplicate_rows = matches.index.get_level_values(1)\n",
    "    \n",
    "    non_dupllicates = df2[~df2.index.isin(duplicate_rows)]\n",
    "    \n",
    "    df = df1.append(df2)\n",
    "except:\n",
    "    pass"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
